- name: Install Ceph with prerequisites
  become: true
  hosts: bootstrapMaster,otherHosts
  vars:
    ceph_release: reef
    docker_compose_version: "2.20.0"
    # NVMe configuration for Ceph OSDs
    nvme_device: "/dev/nvme0n1"  # Primary NVMe device
    force_disk_wipe: false       # Set to true to force wipe even if data exists
    skip_disk_preparation: false # Set to true to skip disk prep if already done
  tasks:
    - name: Ping hosts
      ansible.builtin.ping:

    - name: Update apt packages
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install required system packages
      apt:
        name:
          - curl
          - gnupg
          - lsb-release
          - ca-certificates
          - apt-transport-https
          - software-properties-common
          - python3
          - python3-pip
          - chrony
          - lvm2
          - gdisk
          - parted
        state: present

    - name: Configure NTP synchronization with chrony
      systemd:
        name: chrony
        enabled: yes
        state: started

    - name: Install Docker
      block:
        - name: Create Docker keyring directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Docker GPG key (modern method)
          shell: |
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
          args:
            creates: /etc/apt/keyrings/docker.gpg

        - name: Add Docker repository
          apt_repository:
            repo: "deb [arch=arm64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
            state: present
          when: ansible_architecture == "aarch64"

        - name: Add Docker repository for x86_64
          apt_repository:
            repo: "deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
            state: present
          when: ansible_architecture == "x86_64"

        - name: Install Docker packages
          apt:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: present
            update_cache: yes

        - name: Start and enable Docker
          systemd:
            name: docker
            enabled: yes
            state: started

        - name: Add user to docker group
          user:
            name: "{{ ansible_user }}"
            groups: docker
            append: yes

    - name: Install Ceph repository
      block:
        - name: Create keyring directory for Ceph
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Ceph GPG key
          shell: |
            curl -fsSL https://download.ceph.com/keys/release.asc | gpg --dearmor -o /etc/apt/keyrings/ceph.gpg
          args:
            creates: /etc/apt/keyrings/ceph.gpg

        - name: Add Ceph repository
          apt_repository:
            repo: "deb [signed-by=/etc/apt/keyrings/ceph.gpg] https://download.ceph.com/debian-{{ ceph_release }}/ jammy main"
            state: present

    - name: Update package cache after adding Ceph repo
      apt:
        update_cache: yes

    - name: Install Ceph packages including cephadm
      apt:
        name:
          - cephadm
          - ceph-common
        state: present

    - name: Create ceph directories
      file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      loop:
        - /etc/ceph
        - /var/lib/ceph
        - /var/log/ceph

- name: Prepare NVMe disk for Ceph OSDs
  become: true
  hosts: bootstrapMaster,otherHosts
  tasks:
    - name: Skip disk preparation if requested
      debug:
        msg: "Skipping disk preparation as skip_disk_preparation is set to true"
      when: skip_disk_preparation | bool

    - name: Check if NVMe device exists
      stat:
        path: "{{ nvme_device }}"
      register: nvme_exists
      when: not (skip_disk_preparation | bool)

    - name: Fail if NVMe device not found
      fail:
        msg: "NVMe device {{ nvme_device }} not found on {{ inventory_hostname }}"
      when: 
        - not (skip_disk_preparation | bool)
        - not nvme_exists.stat.exists

    - name: Get NVMe device information
      command: "lsblk {{ nvme_device }} -J"
      register: nvme_info
      changed_when: false
      when: not (skip_disk_preparation | bool)

    - name: Display NVMe device information
      debug:
        msg: |
          NVMe Device: {{ nvme_device }}
          Device Info: {{ nvme_info.stdout | from_json }}
      when: not (skip_disk_preparation | bool)

    - name: Check if device is already used by Ceph
      command: "ceph-volume lvm list {{ nvme_device }}"
      register: ceph_volume_check
      failed_when: false
      changed_when: false
      when: not (skip_disk_preparation | bool)

    - name: Check for existing partitions
      command: "lsblk {{ nvme_device }} -n -o NAME"
      register: nvme_partitions
      changed_when: false
      when: not (skip_disk_preparation | bool)

    - name: Display current partitions
      debug:
        msg: "Current partitions on {{ nvme_device }}: {{ nvme_partitions.stdout_lines }}"
      when: not (skip_disk_preparation | bool)

    - name: Safety check - prevent accidental wipe of system disk
      fail:
        msg: |
          SAFETY CHECK FAILED: {{ nvme_device }} appears to contain mounted filesystems.
          Mounted partitions: {{ ansible_mounts | selectattr('device', 'match', nvme_device + '.*') | map(attribute='device') | list }}
          Set force_disk_wipe=true to override this safety check.
      when: 
        - not (skip_disk_preparation | bool)
        - not (force_disk_wipe | bool)
        - (ansible_mounts | selectattr('device', 'match', nvme_device + '.*') | list | length > 0)

    - name: Warn about data destruction
      debug:
        msg: |
          WARNING: About to prepare {{ nvme_device }} for Ceph OSD usage.
          This will DESTROY ALL DATA on the device!
          Current partitions: {{ nvme_partitions.stdout_lines }}
          Force wipe enabled: {{ force_disk_wipe | bool }}
      when: not (skip_disk_preparation | bool)

    - name: Unmount any mounted partitions on NVMe device
      mount:
        path: "{{ item }}"
        state: unmounted
      loop: "{{ ansible_mounts | selectattr('device', 'match', nvme_device + '.*') | map(attribute='mount') | list }}"
      ignore_errors: yes
      when: 
        - not (skip_disk_preparation | bool)
        - (force_disk_wipe | bool) or (ansible_mounts | selectattr('device', 'match', nvme_device + '.*') | list | length == 0)

    - name: Wipe filesystem signatures from NVMe device
      command: "wipefs -af {{ nvme_device }}"
      when: 
        - not (skip_disk_preparation | bool)
        - nvme_partitions.stdout_lines | length > 1  # More than just the device itself

    - name: Remove any existing LVM physical volumes
      command: "pvremove -ff {{ nvme_device }}"
      failed_when: false
      when: 
        - not (skip_disk_preparation | bool)
        - nvme_partitions.stdout_lines | length > 1

    - name: Zero out the beginning of the device
      command: "dd if=/dev/zero of={{ nvme_device }} bs=1M count=100"
      when: 
        - not (skip_disk_preparation | bool)
        - nvme_partitions.stdout_lines | length > 1

    - name: Create GPT partition table
      command: "sgdisk --zap-all {{ nvme_device }}"
      when: not (skip_disk_preparation | bool)

    - name: Wait for device to settle
      pause:
        seconds: 3
      when: not (skip_disk_preparation | bool)

    - name: Prepare device for Ceph OSD using ceph-volume
      command: "ceph-volume lvm prepare --data {{ nvme_device }}"
      register: ceph_volume_prepare
      when: 
        - not (skip_disk_preparation | bool)
        - ceph_volume_check.rc != 0  # Only if not already prepared

    - name: Display ceph-volume prepare output
      debug:
        var: ceph_volume_prepare.stdout_lines
      when: 
        - ceph_volume_prepare is defined 
        - ceph_volume_prepare.stdout_lines is defined

- name: Bootstrap Ceph cluster (run only on first host)
  become: true
  hosts: bootstrapMaster[0]
  tasks:
    - name: Check if Ceph cluster is already bootstrapped
      stat:
        path: /etc/ceph/ceph.conf
      register: ceph_conf

    - name: Bootstrap Ceph cluster
      command: >
        cephadm bootstrap 
        --mon-ip {{ ansible_default_ipv4.address }}
        --initial-dashboard-user admin
        --initial-dashboard-password admin123
        --allow-fqdn-hostname
      when: not ceph_conf.stat.exists
      register: bootstrap_result

    - name: Display bootstrap output
      debug:
        var: bootstrap_result.stdout_lines
      when: bootstrap_result is defined and bootstrap_result.stdout_lines is defined

    - name: Wait for Ceph cluster to be ready
      command: ceph status
      register: ceph_status
      until: ceph_status.rc == 0
      retries: 30
      delay: 10
      when: not ceph_conf.stat.exists

    - name: Get Ceph public key
      command: ceph cephadm get-pub-key
      register: ceph_pub_key
      when: not ceph_conf.stat.exists

    - name: Copy Ceph public key to other hosts
      authorized_key:
        user: root
        key: "{{ ceph_pub_key.stdout }}"
      delegate_to: "{{ item }}"
      loop: "{{ groups['otherHosts'] }}"
      when: not ceph_conf.stat.exists and item != inventory_hostname

- name: Add hosts to Ceph cluster
  become: true
  hosts: otherHosts
  tasks:
    - name: Check if host is already in cluster
      command: ceph orch host ls --format json
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      register: host_list
      changed_when: false

    - name: Add host to Ceph cluster
      command: >
        ceph orch host add {{ inventory_hostname }} {{ ansible_default_ipv4.address }}
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      when: inventory_hostname not in (host_list.stdout | from_json | map(attribute='hostname') | list)

- name: Configure Ceph services
  become: true
  hosts: bootstrapMaster[0]
  tasks:
    - name: Apply monitor placement
      command: >
        ceph orch apply mon --placement="{{ groups['otherHosts'] | join(',') }}"

    - name: Apply manager placement
      command: >
        ceph orch apply mgr --placement="{{ groups['otherHosts'][:2] | join(',') }}"

    - name: Check for available devices for OSDs
      command: ceph orch device ls --format json
      register: available_devices

    - name: Display available devices
      debug:
        var: available_devices.stdout | from_json

    - name: List prepared LVM volumes for Ceph
      command: ceph-volume lvm list --format json
      register: ceph_lvm_volumes
      changed_when: false

    - name: Display prepared LVM volumes
      debug:
        var: ceph_lvm_volumes.stdout | from_json
      when: ceph_lvm_volumes.stdout != ""

    - name: Activate prepared OSDs using ceph-volume
      command: ceph-volume lvm activate --all
      register: activate_result
      when: ceph_lvm_volumes.stdout != ""

    - name: Display activation results
      debug:
        var: activate_result.stdout_lines
      when: activate_result is defined and activate_result.stdout_lines is defined

    - name: Alternative - Create OSDs on available raw devices (if no LVM volumes prepared)
      command: ceph orch daemon add osd {{ item.hostname }}:{{ item.path }}
      loop: "{{ available_devices.stdout | from_json }}"
      when: 
        - item.available
        - not item.rejected_reasons
        - ceph_lvm_volumes.stdout == ""
      ignore_errors: yes

    - name: Wait for OSDs to be created and up
      command: ceph osd stat
      register: osd_stat
      until: "'up' in osd_stat.stdout"
      retries: 30
      delay: 10
      ignore_errors: yes

    - name: List all OSDs in the cluster
      command: ceph osd tree
      register: osd_tree

    - name: Display OSD tree
      debug:
        var: osd_tree.stdout_lines

    - name: Display final cluster status
      command: ceph status
      register: final_status

    - name: Show cluster status
      debug:
        var: final_status.stdout_lines
