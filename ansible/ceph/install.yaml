---
- name: Install Ceph prerequisites
  become: true
  hosts: all
  vars:
    ceph_release: reef
  tasks:
    - name: Update apt packages
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install required system packages
      apt:
        name:
          - curl
          - gnupg
          - lsb-release
          - ca-certificates
          - apt-transport-https
          - software-properties-common
          - python3
          - python3-pip
          - chrony
          - lvm2
          - gdisk
          - parted
          - cron
        state: present

    - name: Configure NTP synchronization with chrony
      systemd:
        name: chrony
        enabled: yes
        state: started

    - name: Check if Docker is already installed
      command: docker --version
      register: docker_installed
      changed_when: false
      failed_when: false

    - name: Install Docker
      block:
        - name: Create Docker keyring directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Docker GPG key
          shell: |
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
          args:
            creates: /etc/apt/keyrings/docker.gpg

        - name: Add Docker repository for ARM64
          apt_repository:
            repo: "deb [arch=arm64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
            state: present
          when: ansible_architecture == "aarch64"

        - name: Add Docker repository for x86_64
          apt_repository:
            repo: "deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
            state: present
          when: ansible_architecture == "x86_64"

        - name: Install Docker packages
          apt:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: present
            update_cache: yes

        - name: Start and enable Docker
          systemd:
            name: docker
            enabled: yes
            state: started

        - name: Add user to docker group
          user:
            name: "{{ ansible_user }}"
            groups: docker
            append: yes
      when: docker_installed.rc != 0

- name: Install Ceph
  become: true
  hosts: all
  vars:
    ceph_release: reef
  tasks:
    - name: Check if Ceph packages are already installed
      package:
        name: cephadm
        state: present
      register: cephadm_installed
      check_mode: yes

    - name: Install Ceph repository and packages
      block:
        - name: Create keyring directory for Ceph
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Ceph GPG key
          shell: |
            curl -fsSL https://download.ceph.com/keys/release.asc | gpg --dearmor -o /etc/apt/keyrings/ceph.gpg
          args:
            creates: /etc/apt/keyrings/ceph.gpg

        - name: Add Ceph repository
          apt_repository:
            repo: "deb [signed-by=/etc/apt/keyrings/ceph.gpg] https://download.ceph.com/debian-{{ ceph_release }}/ jammy main"
            state: present

        - name: Update package cache after adding Ceph repo
          apt:
            update_cache: yes

        - name: Install Ceph packages
          apt:
            name:
              - cephadm
              - ceph-common
            state: present
      when: cephadm_installed.changed

    - name: Create ceph directories
      file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      loop:
        - /etc/ceph
        - /var/lib/ceph
        - /var/log/ceph

- name: Bootstrap Ceph cluster (run only on bootstrap master)
  become: true
  hosts: bootstrapMaster
  tasks:
    - name: Check if Ceph cluster is already bootstrapped
      stat:
        path: /etc/ceph/ceph.conf
      register: ceph_conf

    - name: Check if cephadm is available for cluster operations
      command: cephadm shell -- ceph status
      register: ceph_status_check
      changed_when: false
      failed_when: false
      when: ceph_conf.stat.exists

    - name: Set cluster status fact
      set_fact:
        cluster_operational: "{{ ceph_conf.stat.exists and (ceph_status_check is defined) and (ceph_status_check.rc == 0) }}"

    - name: Display cluster status
      debug:
        msg: "Cluster already operational: {{ cluster_operational }}"

    - name: Bootstrap Ceph cluster
      command: >
        cephadm bootstrap 
        --mon-ip {{ ansible_default_ipv4.address }}
        --initial-dashboard-user admin
        --initial-dashboard-password admin123
        --allow-fqdn-hostname
        --skip-firewalld
      when: not cluster_operational
      register: bootstrap_result

    - name: Display bootstrap output
      debug:
        var: bootstrap_result.stdout_lines
      when: bootstrap_result is defined and bootstrap_result.stdout_lines is defined

    - name: Wait for Ceph cluster to be ready
      command: cephadm shell -- ceph status
      register: ceph_status
      until: ceph_status.rc == 0
      retries: 30
      delay: 10
      when: bootstrap_result is defined and bootstrap_result.changed

    - name: Update cluster operational status after bootstrap
      set_fact:
        cluster_operational: true
      when: bootstrap_result is defined and bootstrap_result.changed

    - name: Get Ceph public key for SSH distribution
      command: cephadm shell -- ceph cephadm get-pub-key
      register: ceph_pub_key_result
      when: cluster_operational
      changed_when: false
      ignore_errors: true

    - name: Set public key fact
      set_fact:
        cluster_pub_key: "{{ ceph_pub_key_result.stdout if (ceph_pub_key_result is defined and ceph_pub_key_result.rc == 0 and ceph_pub_key_result.stdout is defined) else '' }}"
      when: cluster_operational

    - name: Debug public key status
      debug:
        msg: "Public key obtained: {{ 'Yes' if (cluster_pub_key is defined and cluster_pub_key != '') else 'No' }}"
- name: Distribute SSH keys and add hosts to cluster
  become: true
  hosts: otherHosts
  tasks:
    - name: Get cluster public key from bootstrap master
      command: cephadm shell -- ceph cephadm get-pub-key
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      register: master_pub_key
      changed_when: false
      ignore_errors: true

    - name: Check if SSH key is already authorized
      shell: |
        if [ -f /root/.ssh/authorized_keys ]; then
          grep -F "{{ master_pub_key.stdout }}" /root/.ssh/authorized_keys
        else
          exit 1
        fi
      register: ssh_key_check
      changed_when: false
      failed_when: false
      when: 
        - master_pub_key is defined
        - master_pub_key.rc == 0
        - master_pub_key.stdout is defined

    - name: Add Ceph SSH key to authorized_keys
      authorized_key:
        user: root
        key: "{{ master_pub_key.stdout }}"
        state: present
      when: 
        - master_pub_key is defined
        - master_pub_key.rc == 0
        - master_pub_key.stdout is defined
        - ssh_key_check.rc != 0

    - name: Check if bootstrap master cluster is accessible
      command: cephadm shell -- ceph status
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      register: cluster_accessible
      changed_when: false
      failed_when: false

    - name: Get current hosts in cluster
      command: cephadm shell -- ceph orch host ls --format json
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      register: host_list
      changed_when: false
      failed_when: false
      when: cluster_accessible.rc == 0

    - name: Parse existing hosts
      set_fact:
        existing_hosts: "{{ (host_list.stdout | from_json | map(attribute='hostname') | list) if (host_list is defined and host_list.rc == 0 and host_list.stdout != '') else [] }}"

    - name: Display current cluster hosts
      debug:
        msg: "Current hosts in cluster: {{ existing_hosts }}, checking for: {{ inventory_hostname }}"
      when: existing_hosts is defined

    - name: Add host to Ceph cluster
      command: >
        cephadm shell -- ceph orch host add {{ inventory_hostname }} {{ ansible_default_ipv4.address }}
      delegate_to: "{{ groups['bootstrapMaster'][0] }}"
      when: 
        - cluster_accessible.rc == 0
        - existing_hosts is defined
        - inventory_hostname not in existing_hosts
      register: host_add_result

    - name: Display host addition result
      debug:
        msg: "Host {{ inventory_hostname }} added to cluster: {{ host_add_result.stdout_lines if host_add_result.stdout_lines is defined else 'Success' }}"
      when: host_add_result is defined and host_add_result.changed

    - name: Confirm host is already in cluster
      debug:
        msg: "Host {{ inventory_hostname }} is already in the cluster"
      when: 
        - existing_hosts is defined
        - inventory_hostname in existing_hosts

- name: Configure Ceph services
  become: true
  hosts: bootstrapMaster
  tasks:
    - name: Verify cluster status before service configuration
      command: cephadm shell -- ceph status
      register: pre_config_status
      changed_when: false
      failed_when: false

    - name: Ensure cluster is operational
      fail:
        msg: "Ceph cluster is not operational. Status check failed."
      when: pre_config_status.rc != 0

    - name: Get all hosts in cluster
      command: cephadm shell -- ceph orch host ls --format json
      register: cluster_hosts_raw
      changed_when: false

    - name: Parse cluster hosts
      set_fact:
        current_cluster_hosts: "{{ (cluster_hosts_raw.stdout | from_json | map(attribute='hostname') | list) | sort if (cluster_hosts_raw.rc == 0 and cluster_hosts_raw.stdout != '') else [] }}"

    - name: Display cluster hosts
      debug:
        msg: "Hosts available for service placement: {{ current_cluster_hosts }}"

    - name: Fail if no hosts in cluster
      fail:
        msg: "No hosts found in cluster"
      when: 
        - current_cluster_hosts | length == 0
        - not ansible_check_mode

    # Monitor service configuration
    - name: Get current monitor placement
      command: cephadm shell -- ceph orch ls mon --format json
      register: mon_placement_raw
      changed_when: false
      ignore_errors: true

    - name: Parse current monitor configuration
      set_fact:
        current_mon_config: "{{ (mon_placement_raw.stdout | from_json)[0] if (mon_placement_raw.rc == 0 and mon_placement_raw.stdout != '' and (mon_placement_raw.stdout | from_json | length > 0)) else {} }}"

    - name: Extract current monitor hosts
      set_fact:
        current_mon_hosts: "{{ (current_mon_config.placement.hosts | sort) if (current_mon_config.placement is defined and current_mon_config.placement.hosts is defined) else [] }}"

    - name: Define target monitor hosts (all hosts)
      set_fact:
        target_mon_hosts: "{{ current_cluster_hosts }}"

    - name: Check if monitor placement needs update
      set_fact:
        update_monitors: "{{ current_mon_hosts != target_mon_hosts and not ansible_check_mode }}"

    - name: Display monitor placement comparison
      debug:
        msg:
          - "Current monitor hosts: {{ current_mon_hosts }}"
          - "Target monitor hosts: {{ target_mon_hosts }}"
          - "Update needed: {{ update_monitors }}"

    - name: Apply monitor placement to all hosts
      command: >
        cephadm shell -- ceph orch apply mon --placement="{{ target_mon_hosts | join(',') }}"
      when: update_monitors
      register: mon_apply_result

    - name: Display monitor placement result
      debug:
        msg: "Monitor placement updated successfully"
      when: mon_apply_result is defined and mon_apply_result.changed

    # Manager service configuration
    - name: Get current manager placement
      command: cephadm shell -- ceph orch ls mgr --format json
      register: mgr_placement_raw
      changed_when: false
      ignore_errors: true

    - name: Parse current manager configuration
      set_fact:
        current_mgr_config: "{{ (mgr_placement_raw.stdout | from_json)[0] if (mgr_placement_raw.rc == 0 and mgr_placement_raw.stdout != '' and (mgr_placement_raw.stdout | from_json | length > 0)) else {} }}"

    - name: Extract current manager hosts
      set_fact:
        current_mgr_hosts: "{{ (current_mgr_config.placement.hosts | sort) if (current_mgr_config.placement is defined and current_mgr_config.placement.hosts is defined) else [] }}"

    - name: Define target manager hosts (first 3 hosts)
      set_fact:
        target_mgr_hosts: "{{ current_cluster_hosts[:3] }}"

    - name: Check if manager placement needs update
      set_fact:
        update_managers: "{{ current_mgr_hosts != target_mgr_hosts and not ansible_check_mode }}"

    - name: Display manager placement comparison
      debug:
        msg:
          - "Current manager hosts: {{ current_mgr_hosts }}"
          - "Target manager hosts: {{ target_mgr_hosts }}"
          - "Update needed: {{ update_managers }}"

    - name: Apply manager placement to first 3 hosts
      command: >
        cephadm shell -- ceph orch apply mgr --placement="{{ target_mgr_hosts | join(',') }}"
      when: update_managers
      register: mgr_apply_result

    - name: Display manager placement result
      debug:
        msg: "Manager placement updated successfully"
      when: mgr_apply_result is defined and mgr_apply_result.changed

    # Wait for changes to propagate
    - name: Wait for service changes to propagate
      pause:
        seconds: 30
        prompt: "Waiting for service placement changes to take effect..."
      when: 
        - not ansible_check_mode
        - (mon_apply_result is defined and mon_apply_result.changed) or (mgr_apply_result is defined and mgr_apply_result.changed)

    # Final status and summary
    - name: Get final cluster status
      command: cephadm shell -- ceph status
      register: final_status
      changed_when: false
      ignore_errors: true

    - name: Display final cluster status
      debug:
        var: final_status.stdout_lines
      when: final_status is defined and final_status.rc == 0

    - name: Get cluster health details
      command: cephadm shell -- ceph health detail
      register: health_detail
      changed_when: false
      ignore_errors: true

    - name: Display health details if not healthy
      debug:
        var: health_detail.stdout_lines
      when: 
        - health_detail is defined 
        - health_detail.rc == 0
        - final_status is defined
        - final_status.rc == 0
        - "'HEALTH_OK' not in final_status.stdout"

    - name: Display installation summary
      debug:
        msg:
          - "=========================================="
          - "     Ceph Cluster Installation Complete!"
          - "=========================================="
          - ""
          - "Cluster Information:"
          - "  Dashboard URL: https://{{ ansible_default_ipv4.address }}:8443"
          - "  Username: admin"
          - "  Password: admin123"
          - ""
          - "Cluster Configuration:"
          - "  Total hosts: {{ current_cluster_hosts | length }}"
          - "  Hosts: {{ current_cluster_hosts | join(', ') }}"
          - "  Monitor hosts: {{ target_mon_hosts | join(', ') }}"
          - "  Manager hosts: {{ target_mgr_hosts | join(', ') }}"
          - ""
          - "Service Updates Applied:"
          - "  Monitors: {{ 'Updated' if (mon_apply_result is defined and mon_apply_result.changed) else 'No changes needed' }}"
          - "  Managers: {{ 'Updated' if (mgr_apply_result is defined and mgr_apply_result.changed) else 'No changes needed' }}"
          - ""
          - "Next Steps:"
          - "1. Add storage devices using ceph-volumes runbook"
          - "2. Create pools and configure storage classes"
          - "3. Configure authentication and users as needed"
          - ""
          - "To re-run this playbook:"
          - "  ansible-playbook -i hosts.yaml install.yaml"
          - "  (This playbook is idempotent and safe to re-run)"
          - "=========================================="
